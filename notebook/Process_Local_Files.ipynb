{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "942a707c",
   "metadata": {},
   "source": [
    "## Workbook for local actions related to the streaming UK Rail workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48fe71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as aw\n",
    "import json\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0a12b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the correct session is used\n",
    "boto3.setup_default_session(region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4829983",
   "metadata": {},
   "source": [
    "Read the location export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64964a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Tiploc</th>\n",
       "      <th>Stanox</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>AACHEN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.767721</td>\n",
       "      <td>6.091281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abercwmboi</td>\n",
       "      <td>ABCWM</td>\n",
       "      <td>78128.0</td>\n",
       "      <td>51.690694</td>\n",
       "      <td>-3.402551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penywaun Bus</td>\n",
       "      <td>ABDAPEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.730537</td>\n",
       "      <td>-3.484104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aberdare</td>\n",
       "      <td>ABDARE</td>\n",
       "      <td>78100.0</td>\n",
       "      <td>51.714525</td>\n",
       "      <td>-3.441859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trecynon</td>\n",
       "      <td>ABDATRE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.721419</td>\n",
       "      <td>-3.459253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11199</th>\n",
       "      <td>Training Location Alpha</td>\n",
       "      <td>ZTRGALP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.593103</td>\n",
       "      <td>-0.000494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11200</th>\n",
       "      <td>Training Location Brian</td>\n",
       "      <td>ZTRGBRI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.593129</td>\n",
       "      <td>0.000923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11201</th>\n",
       "      <td>Training Location Deltad</td>\n",
       "      <td>ZTRGDED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.593161</td>\n",
       "      <td>0.002006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11202</th>\n",
       "      <td>Training Location James</td>\n",
       "      <td>ZTRGJAM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.593154</td>\n",
       "      <td>0.003176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11203</th>\n",
       "      <td>Training Location Kinsey</td>\n",
       "      <td>ZTRGKIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.592632</td>\n",
       "      <td>-0.000483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11204 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Tiploc   Stanox   Latitude  Longitude\n",
       "0                        Aachen   AACHEN      5.0  50.767721   6.091281\n",
       "1                    Abercwmboi    ABCWM  78128.0  51.690694  -3.402551\n",
       "2                  Penywaun Bus  ABDAPEN      NaN  51.730537  -3.484104\n",
       "3                      Aberdare   ABDARE  78100.0  51.714525  -3.441859\n",
       "4                      Trecynon  ABDATRE      NaN  51.721419  -3.459253\n",
       "...                         ...      ...      ...        ...        ...\n",
       "11199   Training Location Alpha  ZTRGALP      NaN  53.593103  -0.000494\n",
       "11200   Training Location Brian  ZTRGBRI      NaN  53.593129   0.000923\n",
       "11201  Training Location Deltad  ZTRGDED      NaN  53.593161   0.002006\n",
       "11202   Training Location James  ZTRGJAM      NaN  53.593154   0.003176\n",
       "11203  Training Location Kinsey  ZTRGKIN      NaN  53.592632  -0.000483\n",
       "\n",
       "[11204 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df = pd.read_json('./LocationData/TiplocPublicExport_2021-07-28_15-45.json')\n",
    "# The read file contains tiplocs in json format - this line reformats those json cells (which \n",
    "# get parsed into dictionaries by pandas) into their own rows\n",
    "df_save_locations = pd.DataFrame((d for d in location_df['Tiplocs']))\n",
    "# Select only the information that is required\n",
    "df_save_locations = df_save_locations[['Name', 'Tiploc', 'Stanox', 'Latitude', 'Longitude']]\n",
    "df_save_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608783c3",
   "metadata": {},
   "source": [
    "Prepare the dataset of locations to save. First obtain the schema\n",
    "of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e16199d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'string',\n",
       " 'tiploc': 'string',\n",
       " 'stanox': 'string',\n",
       " 'latitude': 'double',\n",
       " 'longitude': 'double'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saveSchema = aw.catalog.extract_athena_types(df_save_locations)[0]\n",
    "saveSchema['stanox'] = 'string'\n",
    "saveSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0627b0",
   "metadata": {},
   "source": [
    "Next, deduplicate the locations by stanox (the key for location in the\n",
    "streaming dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5eb98a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stanox</th>\n",
       "      <th>name</th>\n",
       "      <th>tiploc</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Thurso</td>\n",
       "      <td>THURSO</td>\n",
       "      <td>58.589893</td>\n",
       "      <td>-3.527793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10021</td>\n",
       "      <td>Aspatria</td>\n",
       "      <td>ASPTRIA</td>\n",
       "      <td>54.758960</td>\n",
       "      <td>-3.331890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10023</td>\n",
       "      <td>Maryport</td>\n",
       "      <td>MPRT</td>\n",
       "      <td>54.711187</td>\n",
       "      <td>-3.494391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10026</td>\n",
       "      <td>Flimby</td>\n",
       "      <td>FLIMBY</td>\n",
       "      <td>54.689933</td>\n",
       "      <td>-3.520584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003</td>\n",
       "      <td>Thurso UKAEA</td>\n",
       "      <td>THURSOU</td>\n",
       "      <td>58.589065</td>\n",
       "      <td>-3.528059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10097</th>\n",
       "      <td>9541</td>\n",
       "      <td>Rylstone S.B.</td>\n",
       "      <td>RYLSTON</td>\n",
       "      <td>54.030788</td>\n",
       "      <td>-2.053228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10098</th>\n",
       "      <td>9542</td>\n",
       "      <td>Rylstone Tilcon (GBRf)</td>\n",
       "      <td>RYLSGBF</td>\n",
       "      <td>54.050636</td>\n",
       "      <td>-2.023828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10099</th>\n",
       "      <td>9543</td>\n",
       "      <td>Rylstone (swinden) Quarry</td>\n",
       "      <td>RYLSQRY</td>\n",
       "      <td>54.045146</td>\n",
       "      <td>-2.029240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10100</th>\n",
       "      <td>9545</td>\n",
       "      <td>Rylstone Lc</td>\n",
       "      <td>RYLSLC</td>\n",
       "      <td>54.045146</td>\n",
       "      <td>-2.029240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10101</th>\n",
       "      <td>99886</td>\n",
       "      <td>X Test 02</td>\n",
       "      <td>XTEST02</td>\n",
       "      <td>53.583302</td>\n",
       "      <td>0.047260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10102 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stanox                       name   tiploc   latitude  longitude\n",
       "0       1001                     Thurso   THURSO  58.589893  -3.527793\n",
       "1      10021                   Aspatria  ASPTRIA  54.758960  -3.331890\n",
       "2      10023                   Maryport     MPRT  54.711187  -3.494391\n",
       "3      10026                     Flimby   FLIMBY  54.689933  -3.520584\n",
       "4       1003               Thurso UKAEA  THURSOU  58.589065  -3.528059\n",
       "...      ...                        ...      ...        ...        ...\n",
       "10097   9541              Rylstone S.B.  RYLSTON  54.030788  -2.053228\n",
       "10098   9542     Rylstone Tilcon (GBRf)  RYLSGBF  54.050636  -2.023828\n",
       "10099   9543  Rylstone (swinden) Quarry  RYLSQRY  54.045146  -2.029240\n",
       "10100   9545                Rylstone Lc   RYLSLC  54.045146  -2.029240\n",
       "10101  99886                  X Test 02  XTEST02  53.583302   0.047260\n",
       "\n",
       "[10102 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedupe = df_save_locations.groupby('stanox').first().reset_index()\n",
    "dedupe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c73a2",
   "metadata": {},
   "source": [
    "Finaly, save the location dataframe to the location table. First create the table\n",
    "with the schema extracted from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be5f5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "aw.catalog.create_parquet_table(database = \"train_silver\", \n",
    "                                table = \"location\", \n",
    "                                path = \"s3://train-silver/location/\",\n",
    "                                columns_types = saveSchema,\n",
    "                                compression = \"snappy\",\n",
    "                                table_type = \"GOVERNED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db98eaf",
   "metadata": {},
   "source": [
    "And then write the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c9769db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': ['s3://train-silver/location/4e7accbb3c61406d979e6a818e1db2b7.snappy.parquet'],\n",
       " 'partitions_values': {}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aw.s3.to_parquet(\n",
    "            df=dedupe,\n",
    "            dataset=True,\n",
    "            mode=\"append\",\n",
    "            database=\"train_silver\",\n",
    "            table=\"location\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f952240a",
   "metadata": {},
   "source": [
    "## Experimentation zone\n",
    "\n",
    "These cells relate to various bits of experimentation performed to understand how AWS data wrangler works with Athena and Lake Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95bf013",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir, dirs, files in os.walk('./sample_data/'):\n",
    "    for file in files:\n",
    "        file_loc = os.path.join(subdir, file)\n",
    "        f = open(file_loc)\n",
    "        print(file_loc)\n",
    "        filedata = json.load(f)\n",
    "        rows = []\n",
    "        for row in filedata:\n",
    "            row_to_add = row['body']\n",
    "            row_to_add['msg_type'] = row['header']['msg_type']\n",
    "            rows.append(row_to_add)\n",
    "            \n",
    "        frame = pd.DataFrame(rows)        \n",
    "        frame['segment_timestamp'] = np.nan\n",
    "        if 'actual_timestamp' in frame.columns:\n",
    "            frame['segment_timestamp'] = frame['segment_timestamp'].fillna(frame['actual_timestamp'])\n",
    "        if 'creation_timestamp' in frame.columns:\n",
    "            frame['segment_timestamp'] = frame['segment_timestamp'].fillna(frame['creation_timestamp'])\n",
    "        if 'dep_timestamp' in frame.columns:\n",
    "            frame['segment_timestamp'] = frame['segment_timestamp'].fillna(frame['dep_timestamp'])\n",
    "        if 'event_timestamp' in frame.columns:\n",
    "            frame['segment_timestamp'] = frame['segment_timestamp'].fillna(frame['event_timestamp'])\n",
    "                \n",
    "        frame['segment_date'] = frame['segment_timestamp'].apply(lambda x: datetime.fromtimestamp(int(x) / 1000.0).date())\n",
    "        frame = frame.drop(columns=['segment_timestamp'])\n",
    "        print('Calling s3 to parquet')\n",
    "        aw.s3.to_parquet(\n",
    "            df=frame,\n",
    "            dataset=True,\n",
    "            mode=\"append\",\n",
    "            database=\"train_bronze\",\n",
    "            table=\"train_movements_governed\",\n",
    "            catalog_versioning=True,  # Optional\n",
    "            #schema_evolution=True,\n",
    "            partition_cols=['segment_date']\n",
    "        )\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ce041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aw.athena.read_sql_query('SELECT max(canx_timestamp) AS max_date FROM \"AwsDataCatalog\".\"train_silver\".\"journey\";', database=\"train_silver\")\n",
    "df.fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c21cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()['max_date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()[0] == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf95a2d",
   "metadata": {},
   "source": [
    "## Batch Job dev\n",
    "\n",
    "This notebook code was used to test the various elements of the AWS batch job that writes journeys and stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a188ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_journey_timestamp = 0\n",
    "\n",
    "journey_query = \"\"\"SELECT train_id, loc_stanox as stanox, CAST(canx_timestamp as bigint) AS canx_timestamp, segment_date \n",
    "FROM \"AwsDataCatalog\".\"train_bronze\".\"train_movements_governed\" \n",
    "WHERE canx_type = 'AT ORIGIN' \n",
    "AND cast(canx_timestamp AS bigint) > {}\"\"\".format(max_journey_timestamp)\n",
    "\n",
    "print(journey_query)\n",
    "\n",
    "\n",
    "journey_df = aw.athena.read_sql_query(journey_query, database=\"train_bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "journey_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde92ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "journey_df = aw.athena.read_sql_query('SELECT count(*) as all_journey_count FROM \"train_silver\".\"journey\";', database=\"train_silver\")\n",
    "journey_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c44797",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_df = aw.athena.read_sql_query('SELECT count(*) as all_journey_count FROM \"train_silver\".\"stop\";', database=\"train_silver\")\n",
    "stop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dcdeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aw.athena.read_sql_query('SELECT max(canx_timestamp) AS max_date FROM \"AwsDataCatalog\".\"train_silver\".\"journey\";', database=\"train_silver\")\n",
    "max_journey_timestamp = df.head()['max_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64e607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_journey_timestamp = df.head()['max_date'][0]\n",
    "max_journey_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b88ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT a.train_id, a.loc_stanox as stanox_code, \n",
    "       a.planned_timestamp as planned_arrival_int, \n",
    "       a.actual_timestamp as actual_arrival_int,\n",
    "       a.variation_status as time_status,\n",
    "       b.planned_timestamp as planned_departure_int, \n",
    "       b.actual_timestamp as actual_departure_int,\n",
    "       CASE a.planned_event_type \n",
    "           WHEN 'DESTINATION' THEN True\n",
    "           ELSE False\n",
    "       END AS is_terminus\n",
    "FROM \"train_bronze\".\"train_movements_governed\" as a\n",
    "     LEFT JOIN \"train_bronze\".\"train_movements_governed\" as b\n",
    "     ON  a.train_id = b.train_id\n",
    "     AND a.loc_stanox = b.loc_stanox\n",
    "     AND a.event_type = 'ARRIVAL'  \n",
    "     AND b.event_type = 'DEPARTURE'  \n",
    "WHERE a.event_type = 'ARRIVAL'  \n",
    "AND (b.event_type = 'DEPARTURE' or a.planned_event_type = 'DESTINATION') \n",
    "AND (CAST(a.actual_timestamp as bigint) > {} OR CAST(b.actual_timestamp as bigint) > {})\"\"\".format(0, 0)\n",
    "\n",
    "stop_df = aw.athena.read_sql_query(query, database=\"train_bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb43a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_df['planned_departure_int'] = stop_df['planned_departure_int'].fillna('0')\n",
    "stop_df['actual_departure_int'] = stop_df['actual_departure_int'].fillna('0')\n",
    "\n",
    "def calc_date(planned, actual):\n",
    "    if planned == 0:\n",
    "        return datetime.fromtimestamp(int(actual) / 1000.0)\n",
    "    return datetime.fromtimestamp(int(planned) / 1000.0)\n",
    "\n",
    "def value_with_fallback(value, fallback):\n",
    "    if value == 0:\n",
    "        return fallback\n",
    "    return value\n",
    "\n",
    "def calc_date_none(actual):\n",
    "    if actual == 0:\n",
    "        return None\n",
    "    return datetime.fromtimestamp(int(actual) / 1000.0)\n",
    "\n",
    "def calc_delay(expected, actual):\n",
    "    if expected == 0 or actual == 0:\n",
    "        return 0\n",
    "    return (actual - expected) / 1000.0\n",
    "\n",
    "stop_df[\"arrival\"] = stop_df['actual_arrival_int'].apply(lambda x: datetime.fromtimestamp(int(x) / 1000.0))\n",
    "stop_df[\"planned_arrival_int\"].replace({\"\": \"0\"}, inplace=True)\n",
    "stop_df[\"delay_seconds\"] = stop_df.apply(lambda x: calc_delay(int(x['planned_arrival_int']), int(x['actual_arrival_int'])), axis=1)\n",
    "stop_df[\"planned_arrival\"] = stop_df.apply(lambda x: calc_date(int(x['planned_arrival_int']), int(x['actual_arrival_int'])), axis=1)\n",
    "\n",
    "stop_df[\"planned_departure_int\"].replace({\"\": \"0\"}, inplace=True)\n",
    "stop_df[\"departure\"] = stop_df['actual_departure_int'].apply(lambda x: calc_date_none(x))\n",
    "stop_df[\"planned_departure\"] = stop_df['planned_departure_int'].apply(lambda x: calc_date_none(x))\n",
    "stop_df[\"depart_timestamp\"] = stop_df.apply(lambda x: value_with_fallback(int(x['actual_departure_int']), int(x['actual_arrival_int'])), axis=1)\n",
    "\n",
    "stop_df.drop(['planned_arrival_int', 'actual_arrival_int', 'planned_departure_int', 'actual_departure_int'], inplace=True, axis=1)\n",
    "stop_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aw.athena.read_sql_query('SELECT * FROM \"AwsDataCatalog\".\"train_silver\".\"stop\" LIMIT 50;', database=\"train_silver\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6e4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
